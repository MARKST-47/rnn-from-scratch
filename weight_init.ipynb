{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.3898,  0.1902],\n",
      "        [ 0.9608, -1.0769],\n",
      "        [-0.4479, -1.0935]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.linear = nn.Linear(2, 3)  # Define a linear layer\n",
    "\n",
    "        # Apply Xavier initialization\n",
    "        nn.init.xavier_uniform_(self.linear.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "# Create an instance of the model\n",
    "model = MyModel()\n",
    "\n",
    "# Print the initialized weights\n",
    "print(model.linear.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In PyTorch, the choice of weight initialization technique can significantly impact the training and performance of neural networks. Hereâ€™s a brief guide on when to use each method:\n",
    "\n",
    "### Xavier (Glorot) Initialization\n",
    "\n",
    "- **When to Use**: \n",
    "  - Best suited for layers with **sigmoid** or **tanh** activation functions.\n",
    "  - Helps maintain the variance of activations across layers, preventing vanishing or exploding gradients.\n",
    "\n",
    "- **How to Implement**:\n",
    "  - Use `torch.nn.init.xavier_uniform_()` for uniform distribution or `torch.nn.init.xavier_normal_()` for normal distribution.\n",
    "\n",
    "### Kaiming (He) Initialization\n",
    "\n",
    "- **When to Use**:\n",
    "  - Recommended for layers with **ReLU** or **Leaky ReLU** activation functions.\n",
    "  - Specifically designed to account for the non-linearity of ReLU, which can lead to dead neurons if weights are not initialized properly.\n",
    "\n",
    "- **How to Implement**:\n",
    "  - Use `torch.nn.init.kaiming_uniform_()` or `torch.nn.init.kaiming_normal_()`.\n",
    "\n",
    "### Summary\n",
    "\n",
    "- Use **Xavier Initialization** for sigmoid/tanh activations to stabilize gradients.\n",
    "- Use **Kaiming Initialization** for ReLU activations to enhance learning efficiency and avoid dead neurons. \n",
    "\n",
    "Choosing the appropriate initialization method can lead to faster convergence and better overall performance in training neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0571,  0.6348],\n",
      "        [-0.4832, -0.2329],\n",
      "        [ 0.1129, -0.2058]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "class MyModel2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel2, self).__init__()\n",
    "        self.linear = nn.Linear(2, 3)  # Define a linear layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "# Create an instance of the model\n",
    "model = MyModel2()\n",
    "\n",
    "# Print the initialized weights\n",
    "print(model.linear.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0337, -0.2174],\n",
      "        [ 0.2005, -0.4811],\n",
      "        [ 0.0487, -0.2465]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "class MyModel3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel3, self).__init__()\n",
    "        self.linear = nn.Linear(2, 3)  # Define a linear layer\n",
    "        nn.init.xavier_normal_(self.linear.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "# Create an instance of the model\n",
    "model = MyModel3()\n",
    "\n",
    "# Print the initialized weights\n",
    "print(model.linear.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_alternating_sequence(arr):\n",
    "    if not arr:  # if the list is empty\n",
    "        return 0\n",
    "    \n",
    "    max_count = 1  # Start with 1 as a minimum count\n",
    "    current_count = 1  # Current sequence count\n",
    "    \n",
    "    for i in range(1, len(arr)):\n",
    "        if arr[i] != arr[i - 1]:  # If current element is different from the previous\n",
    "            current_count += 1\n",
    "        else:  # Reset the sequence when a repeat is found\n",
    "            max_count = max(max_count, current_count)\n",
    "            current_count = 1  # Restart the count with the new sequence\n",
    "            \n",
    "    # Final comparison to check the last sequence\n",
    "    max_count = max(max_count, current_count)\n",
    "    \n",
    "    return max_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "5\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "arr1 = [0]\n",
    "arr2 = [0, 1, 0, 1, 0]\n",
    "arr3 = [0, 1, 0, 1, 0, 1, 1, 1, 0]  # Expected output: 2\n",
    "print(max_alternating_sequence(arr1))  # Output: 1\n",
    "print(max_alternating_sequence(arr2))  # Output: 5\n",
    "print(max_alternating_sequence(arr3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
